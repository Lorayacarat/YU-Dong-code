# 加载必要的包
library(glmnet)
library(caret)
library(pROC)
library(ggplot2)
library(rms)
library(dplyr)
library(ROCR)
#install.packages("openxlsx")

library(openxlsx)
rm(list = ls())#清空环境
# 读取数据 
data <- read.csv("D:/R/analysis/data_all_reviewed.csv")
# 将 Group.0.normal.1.COPD. 列转换为因子，并重命名为 "non-COPD" 和 "COPD"
data$Group.0.normal.1.COPD. <- factor(data$Group.0.normal.1.COPD., 
                                      levels = c(0, 1),  # 按照 0 和 1 的顺序排列因子
                                      labels = c("non-COPD", "COPD"))  # 使用 'non-COPD' 和 'COPD' 重命名因子


# 定义所有列名的原始和新列名映射
colnames_map <- c(
  "Characteristic" = "Characteristic",
  "Age" = "Age (years)",
  "Height" = "Height(cm)",
  "Weight" = "Weight(kg)",
  "BMI" = "BMI (kg/m2)",
  "Smoking.Index" = "Smoking Index",
  "VC.pred." = "VC pred",
  "VC.Act1." = "VC Act",
  "VC..Act1.Pred." = "VC %Act/Pred",
  "FVC.pred." = "FVC pred",
  "FVC.Act1." = "FVC Act1",
  "FVC..Act1.Pred." = "FVC %Act1/Pred",
  "FEV1.pred." = "FEV1 pred",
  "FEV1.Act1." = "FEV1 Act1",
  "FEV1..Act1.Pred." = "FEV1 %Act1/Pred",
  "FEV1.VC.pred." = "FEV1/VC pred",
  "FEV1.VC.Act1." = "FEV1/VC Act1",
  "FEV1.VC..Act1.Pred." = "FEV1/VC %Act1/Pred",
  "FEV1.FVC.pred." = "FEV1/FVC pred",
  "FEV1.FVC.Act1." = "FEV1/FVC Act",
  "FEV1.FVC..Act1.Pred." = "FEV1/FVC %Act/Pred",
  "PEF.pred." = "PEF pred",
  "PEF.Act1." = "PEF Act",
  "PEF..Act1.Pred." = "PEF %Act1/Pred",
  "MMEF..Act1.Pred." = "MMEF %Act1/Pred",
  "MVV.Pred." = "MVV Pred",
  "T.Rt.diaphragmatic.motion..mm." = "T-Rt diaphragmatic motion(mm)",
  "T.Lt.diaphragmatic.motion..mm." = "T-Lt diaphragmatic motion(mm)",
  "T.Rt..Maximum.projected.lung.area.mm2." = "T-Rt Maximum PLA (mm2)",
  "T.Lt..Maximum.projected.lung.area.mm2." = "T Lt Maximum PLA (mm2)",
  "T.Rt.Lt.Maximum.projected.lung.area.mm2." = "T- Rt+Lt Maximum PLA (mm2)",
  "T.Rt..Minimum.projected.lung.area.mm2." = "T-Rt Minimum PLA (mm2)",
  "T.Lt..Minimum.projected.lung.area.mm2." = "T-Lt Minimum PLA (mm2)",
  "T.Rt.Lt..Minimum.projected.lung.area.mm2." = "T- Rt+Lt Minimum PLA (mm2)",
  "T.Rt.projected.lung.area.change.rate...." = "T-Rt ΔPLA (%)",
  "T.Lt.projected.lung.area.change.rate...." = "T-Lt ΔPLA (%)",
  "T.Rt.Lt.projected.lung.area.change.rate...." = "T- Rt+Lt ΔPLA (%)",
  "D.Rt.diaphragmatic.motion..mm." = "D-Rt diaphragmatic motion(mm)",
  "D.Lt.diaphragmatic.motion..mm." = "D-Lt diaphragmatic motion(mm)",
  "D.Rt..Maximum.projected.lung.area.mm2." = "D-Rt Maximum PLA (mm2)",
  "D.Lt..Maximum.projected.lung.area.mm2." = "D-Lt Maximum PLA (mm2)",
  "D.Rt.Lt.Maximum.projected.lung.area.mm2." = "D- Rt+Lt Maximum PLA (mm2)",
  "D.Rt..Minimum.projected.lung.area.mm2." = "D-Rt Minimum PLA (mm2)",
  "D.Lt..Minimum.projected.lung.area.mm2." = "D-Lt Minimum PLA (mm2)",
  "D.Rt.Lt..Minimum.projected.lung.area.mm2." = "D- Rt+Lt Minimum PLA (mm2)",
  "D.Rt.projected.lung.area.change.rate...." = "D-Rt ΔPLA (%)",
  "D.Lt.projected.lung.area.change.rate...." = "D-Lt ΔPLA (%)",
  "D.Rt.Lt.projected.lung.area.change.rate...." = "D- Rt+Lt ΔPLA (%)",
  "Sex.0.female.1.male." = "Sex",
  "Smoking.0.No.1.Yes." = "Smoking",
  "Group.0.normal.1.COPD." = "COPD VS non-COPD"
)

# 修改数据框列名
colnames(data) <- sapply(colnames(data), function(x) {
  if (x %in% names(colnames_map)) {
    colnames_map[x]
  } else {
    x
  }
})



# 查看结果
str(data)

############################################################################
# 分割数据
if(FALSE)
{
  set.seed(20241226)
  trainIndex <- createDataPartition(data$`COPD VS non-COPD`, p = 0.7, list = FALSE, times = 1)
  
  data_train <- data[trainIndex, ]  # 训练集
  data_test <- data[-trainIndex, ] # 测试集
  
}







# 加载必要的包
library(glmnet)
library(caret)
library(pROC)
library(ggplot2)
library(rms)
library(dplyr)
# 读取数据 
#data <- read.csv("D:/R/analysis/data_all_reviewed.csv")

# 提取自变量和因变量
# 提取自变量和因变量
X <- data[, c(
  "T-Rt diaphragmatic motion(mm)", 
  "T-Lt diaphragmatic motion(mm)", "T-Rt Maximum PLA (mm2)", 
  "T Lt Maximum PLA (mm2)", "T- Rt+Lt Maximum PLA (mm2)", 
  "T-Rt Minimum PLA (mm2)", "T-Lt Minimum PLA (mm2)", 
  "T- Rt+Lt Minimum PLA (mm2)", "T-Rt ΔPLA (%)", "T-Lt ΔPLA (%)", 
  "T- Rt+Lt ΔPLA (%)", "D-Rt diaphragmatic motion(mm)", 
  "D-Lt diaphragmatic motion(mm)", "D-Rt Maximum PLA (mm2)", 
  "D-Lt Maximum PLA (mm2)", "D- Rt+Lt Maximum PLA (mm2)", 
  "D-Rt Minimum PLA (mm2)", "D-Lt Minimum PLA (mm2)", 
  "D- Rt+Lt Minimum PLA (mm2)", "D-Rt ΔPLA (%)", "D-Lt ΔPLA (%)", 
  "D- Rt+Lt ΔPLA (%)"
)]

y <- data$`COPD VS non-COPD`


# 分割训练集和测试集，原始数据加original后缀
set.seed(20241226)
trainIndex <- createDataPartition(y, p = .7, list = FALSE, times = 1)
X_train_original <- X[trainIndex, ]
X_test_original <- X[-trainIndex, ]

# Step 1: 对整个数据集 X 标准化,为标准X
#X_scaled <- scale(X)  # 使用全数据的均值和标准差进行标准化，绝对不行，会泄露数据
#str(X)
X_train <- X_train_original  # 不标准化后的训练集
X_test <- X_test_original  # 不标准化后的测试集
# 创建 y_train 和 y_test
y_train <- y[trainIndex]
y_test <- y[-trainIndex]

# 创建原始训练集和测试集的数据框
df_train_original <- cbind(X_train_original, y = y_train)
df_test_original <- cbind(X_test_original, y = y_test)

# 创建标准化后的训练集和测试集
df_train <- cbind(X_train, y = y_train)
df_test <- cbind(X_test, y = y_test)
# 将矩阵转换为数据框
df_train <- as.data.frame(df_train)
df_test <- as.data.frame(df_test)
# 检查结果
str(df_train_original)
str(df_test_original)
str(df_train)
str(df_test)
# ================================
# 拟合 Lasso 回归模型(未定lambda值)
# ================================
fit <- glmnet(X_train, y_train, alpha = 1, family = "binomial")  # family 可以设置为 "gaussian", "binomial", "poisson" 等

# 设置边框加粗和轴标签字体加粗，同时调整标签位置
par(lwd = 2, font.lab = 2, cex.lab = 1.5, cex.axis = 1.2, mgp = c(2.7, 1, 0))  
# mgp 参数控制轴标题和刻度线的位置

# 生成回归系数路径图
plot(
  fit, 
  xvar = "lambda", 
  label = FALSE,               # 隐藏左侧变量编号
  lwd = 2                      # 加粗线条
)

# 通过交叉验证选择最佳的 lambda 值
cv_fit <- cv.glmnet(as.matrix(X_train), y_train, family = "binomial", alpha = 1)
# 查看交叉验证误差图
plot(cv_fit)


# ================================
#计算最好的两个lambda，提取系数
# ================================

# 提取 lambda.min 和 lambda.1se 值
lambda_min <- cv_fit$lambda.min
lambda_1se <- cv_fit$lambda.1se

# 输出 lambda.min 下的系数
coef_min <- coef(cv_fit, s = "lambda.min")
cat("Lambda.min:", lambda_min, "\n")
cat("Coefficients at lambda.min:\n")
print(coef_min)

# 输出 lambda.1se 下的系数
coef_1se <- coef(cv_fit, s = "lambda.1se")
cat("\nLambda.1se:", lambda_1se, "\n")
cat("Coefficients at lambda.1se:\n")
print(coef_1se)



# 将 coef_1se 转换为普通矩阵
coef_1se_matrix <- as.matrix(coef_1se)

# 获取非零系数的变量名
non_zero_features <- rownames(coef_1se_matrix)[coef_1se_matrix[, 1] != 0]
str(non_zero_features)


selected_features <- rownames(coef_1se)[coef_1se[, 1] != 0 & rownames(coef_1se) != "(Intercept)"]



# 查看交叉验证误差图，标注两个最佳lambda值线
plot(cv_fit)
abline(v = log(cv_fit$lambda.min), col = "blue", lty = 2) # lambda.min 位置
abline(v = log(cv_fit$lambda.1se), col = "red", lty = 2)  # lambda.1se 位置
# 在图中标注 lambda.min 和 lambda.1se
# 添加图例，标出 lambda.min 和 lambda.1se
legend("topright", inset = c(0.01, 0.0025), 
       legend = c("lambda.min", "lambda.1se"),
       col = c("blue", "red"), lty = 2, box.lty = 0)


# 基于筛选出的变量重新构建数据集
X_train_selected <- X_train[, selected_features]
X_train_selected <- as.data.frame(X_train_selected)
X_test_selected <- X_test[, selected_features]
X_test_selected <- as.data.frame(X_test_selected)

summary(X_train_selected)
summary(X_test_selected)


# ================================
######用rms 包中的 lrm模型
# ================================

df_train_selected <- df_train_original[, c("y", selected_features)]
df_test_selected <- df_test_original[, c("y", selected_features)]
str(df_train_selected)
str(df_test_selected)
##df_all_selected
# 合并数据框
#df_all_selected <- rbind(df_train_selected, df_test_selected)
# 定义数据的分布信息
dd <- datadist(df_train_selected)
options(datadist = "dd")

######## 拟合 Logistic 回归模型
# 提取自变量列名称（去除响应变量 y）
predictor_vars <- setdiff(colnames(df_train_selected), "y")

# 检查是否有需要加反引号的列
predictor_vars <- ifelse(grepl("[^a-zA-Z0-9_.]", predictor_vars), 
                         paste0("`", predictor_vars, "`"), 
                         predictor_vars)

# 自动构建公式
formula <- as.formula(paste("y ~", paste(predictor_vars, collapse = " + ")))

# 拟合 Logistic 回归模型
fit_rms <- lrm(formula, data = df_train_selected, x = TRUE, y = TRUE)
# ================================
# 查看模型结果，包括估计系数、Z 值、P 值
# ================================

print(fit_rms)




# ================================
# 提取回归系数和标准误
# ================================
coef_estimates <- coef(fit_rms)  # 回归系数
se <- sqrt(diag(vcov(fit_rms)))  # 标准误

# 计算置信区间的下限和上限
z_value <- 1.96  # 95% 置信水平的 z 值
lower_ci <- coef_estimates - z_value * se
upper_ci <- coef_estimates + z_value * se

# ================================
# 计算 OR 和 OR 的置信区间
# ================================
OR <- exp(coef_estimates)
lower_or_ci <- exp(lower_ci)
upper_or_ci <- exp(upper_ci)

# 合并 OR 和置信区间
OR_results <- cbind(OR, lower_or_ci, upper_or_ci)
colnames(OR_results) <- c("Odds Ratio", "Lower 95% CI", "Upper 95% CI")

# 查看 OR 和置信区间
print(OR_results)


# ================================
######### 训练集 C-统计量 Bootstrap 方法
# ================================
library(boot)
library(rms)

# 定义 Bootstrap 计算 C-统计量的函数
c_statistic_bootstrap <- function(data, indices) {
  # 重采样数据
  d <- data[indices, ]
  
  # 重新计算预测概率
  predicted <- predict(fit_rms, newdata = d, type = "fitted")
  
  # 计算 Somers' D 值并转换为 C-统计量
  somers <- somers2(predicted, d$y)
  return(somers["C"])
}

# 准备训练集数据
train_data <- data.frame(y = df_train_selected$y, df_train_selected, check.names = FALSE)
# 检查 y 列的类型和唯一值，确保是数值型
str(train_data$y)
unique(train_data$y)

# 如果 y 是因子类型，转换为二分类数值型 (0 和 1)
train_data$y <- as.numeric(train_data$y) - 1  # 转换为 0/1

# 确认转换后的值
unique(train_data$y)  # 应输出 0 和 1
str(train_data$y)
# 使用 boot() 函数进行 Bootstrap
set.seed(20241001)  # 设置随机种子以保证结果可重复
bootstrap_train <- boot(data = train_data, statistic = c_statistic_bootstrap, R = 1000)

# 提取 C-统计量均值和置信区间
c_stat_train_mean <- mean(bootstrap_train$t)
ci_train <- boot.ci(bootstrap_train, type = "perc")$percent[4:5]

# 输出训练集结果
cat("训练集 C-统计量 (Bootstrap):", c_stat_train_mean, "\n")
cat("训练集 C-统计量 95% CI (Bootstrap):", ci_train, "\n\n")


# ================================
######### 测试集 C-统计量 Bootstrap 方法
# ================================

# 准备测试集数据
test_data <- data.frame(y = df_test_selected$y, df_test_selected, check.names = FALSE)
# 检查 y 列的类型和唯一值，确保是数值型
str(test_data$y)
unique(test_data$y)

# 如果 y 是因子类型，转换为二分类数值型 (0 和 1)
test_data$y <- as.numeric(test_data$y) - 1  # 转换为 0/1

# 确认转换后的值
unique(test_data$y)  # 应输出 0 和 1
str(test_data$y)
# 使用 boot() 函数进行 Bootstrap
bootstrap_test <- boot(data = test_data, statistic = c_statistic_bootstrap, R = 1000)

# 提取 C-统计量均值和置信区间
c_stat_test_mean <- mean(bootstrap_test$t)
ci_test <- boot.ci(bootstrap_test, type = "perc")$percent[4:5]

# 输出测试集结果
cat("测试集 C-统计量 (Bootstrap):", c_stat_test_mean, "\n")
cat("测试集 C-统计量 95% CI (Bootstrap):", ci_test, "\n")

# ================================
########使用 rms 包中的 calibrate 函数绘制train校准曲线
# ================================

# 校准模型（使用 1000 次 Bootstrap）
cal_train <- calibrate(fit_rms, method = "boot", B = 1000)

# 绘制校准曲线
plot(
  cal_train,
  xlim = c(0, 1),
  ylim = c(0, 1),
  xlab = "Predicted Probability",
  ylab = "Observed Probability",
  cex.lab = 1.2,      # 坐标轴标签字体大小
  cex.axis = 1,       # 坐标轴刻度字体大小
  cex.main = 1.2,     # 主标题字体大小
  cex.sub = 0.8,      # 副标题字体大小
  legend = FALSE      # 不显示默认图例
)

# 添加 Bias-corrected 曲线（校正后的校准曲线）
lines(
  cal_train[, c("predy", "calibrated.corrected")],
  type = 'l',          # 连线类型
  lwd = 3,             # 线宽
  col = "#2166AC"      # 校正曲线颜色
)

# 添加 Apparent 曲线（原始校准曲线）
lines(
  cal_train[, c("predy", "calibrated.orig")],
  type = "l",
  lwd = 3,             # 线宽
  col = "tomato"       # 原始曲线颜色
)

# 添加理想线（Ideal Line）
abline(
  0, 1,
  lty = 2,             # 对角线虚线
  lwd = 2,             # 对角线线宽
  col = "#224444"      # 对角线颜色
)

# 添加图例
legend(
  "bottomright",
  legend = c("Apparent", "Bias-corrected", "Ideal"),
  col = c("tomato", "#2166AC", "#224444"),
  lty = c(1, 1, 2),
  lwd = c(3, 3, 2),
  bty = "n"            # 不绘制图例边框
)

# 添加标题
title(main = "Calibration Curve: Train Set")



# ================================
#########使用 rms 包中的 calibrate 函数绘制test校准曲线
# ================================
# 首先获取测试集的预测值
phat <- predict(fit_rms, newdata = df_test_selected, type = "fitted")
df_test_selected$phat <- phat  # 将预测概率添加到测试集中

# 在测试集中用预测值 phat 作为自变量，真实结果 y 作为因变量建立逻辑回归
fit_test <- lrm(y ~ phat, data = df_test_selected, x = TRUE, y = TRUE)

# 校准模型（使用 1000 次 Bootstrap）
cal_test <- calibrate(fit_test, method = "boot", B = 1000)

# 绘制校准曲线
plot(
  cal_test,
  xlim = c(0, 1),
  ylim = c(0, 1),
  xlab = "Predicted Probability",
  ylab = "Observed Probability",
  cex.lab = 1.2,      # 坐标轴标签字体大小
  cex.axis = 1,       # 坐标轴刻度字体大小
  cex.main = 1.2,     # 主标题字体大小
  cex.sub = 0.8,      # 副标题字体大小
  legend = FALSE      # 不显示默认图例
)

# 添加 Bias-corrected 曲线（校正后的校准曲线）
lines(
  cal_test[, c("predy", "calibrated.corrected")],
  type = 'l',          # 连线类型
  lwd = 3,             # 线宽
  col = "#2166AC"      # 校正曲线颜色
)

# 添加 Apparent 曲线（原始校准曲线）
lines(
  cal_test[, c("predy", "calibrated.orig")],
  type = "l",
  lwd = 3,             # 线宽
  col = "tomato"       # 原始曲线颜色
)

# 添加理想线（Ideal Line）
abline(
  0, 1,
  lty = 2,             # 对角线虚线
  lwd = 2,             # 对角线线宽
  col = "#224444"      # 对角线颜色
)

# 添加图例
legend(
  "bottomright",
  legend = c("Apparent", "Bias-corrected", "Ideal"),
  col = c("tomato", "#2166AC", "#224444"),
  lty = c(1, 1, 2),
  lwd = c(3, 3, 2),
  bty = "n"            # 不绘制图例边框
)

# 添加标题
title(main = "Calibration Curve: Test Set")

# 恢复测试集原始数据框（删除 phat 列）
df_test_selected <- df_test_selected %>% select(-phat)

# ================================
#############决策曲线绘制
# ================================
# 加载 rmda 包
library(rmda)

# Step 1: 定义数据的分布信息，以支持 rms 包的其他功能
dd_dca <- datadist(df_train_selected)
options(datadist = "dd_dca")

# Step 2: 使用 rms 包中的 lrm 函数拟合 Logistic 回归模型
# 提取自变量列名称（去除响应变量 y）
predictor_vars_dca <- setdiff(colnames(df_train_selected), "y")
# 检查并为特殊字符的变量名添加反引号
predictor_vars_dca <- ifelse(grepl("[^a-zA-Z0-9_.]", predictor_vars_dca),
                             paste0("`", predictor_vars_dca, "`"),
                             predictor_vars_dca)
# 自动构建公式
formula_dca <- as.formula(paste("y ~", paste(predictor_vars_dca, collapse = " + ")))

# 使用 rms 包中的 lrm 函数拟合 Logistic 回归模型
fit_rms_dca <- lrm(formula_dca, data = df_train_selected, x = TRUE, y = TRUE)

# Step 3: 生成新的数据框用于存储预测风险
df_train_dca <- df_train_selected
df_test_dca <- df_test_selected

# 计算训练集和测试集上的预测风险
df_train_dca$predicted_risk <- predict(fit_rms_dca, newdata = df_train_dca, type = "fitted")
df_test_dca$predicted_risk <- predict(fit_rms_dca, newdata = df_test_dca, type = "fitted")

# 检查 y 的结构
str(df_train_dca$y)

# 检查 y 的唯一值
unique(df_train_dca$y)

# 如果 y 是因子或字符型，转换为 0 和 1
df_train_dca$y <- ifelse(df_train_dca$y == "non-COPD", 0, 1)

# 确保 y 为数值型
df_train_dca$y <- as.numeric(df_train_dca$y)
unique(df_train_dca$y)
str(df_train_dca$y)

# 检查并转换 y 为二分类数值型
df_test_dca$y <- ifelse(df_test_dca$y == "non-COPD", 0, 1)
df_test_dca$y <- as.numeric(df_test_dca$y)

# 验证转换后的 y
print(unique(df_test_dca$y))
print(str(df_test_dca))

# Step 4: 使用 rmda 包的 decision_curve 函数计算 DCA 曲线
# 训练集 DCA
dca_train <- decision_curve(
  y ~ predicted_risk, 
  data = df_train_dca, 
  fitted.risk = TRUE,  # 已提供预测风险值，不需重新拟合模型
  thresholds = seq(0, 1, by = 0.01),  # 设置阈值范围
  confidence.intervals = FALSE,  # 不计算置信区间
  bootstraps = 0  # 不使用 Bootstrap
)

# 测试集 DCA
dca_test <- decision_curve(
  y ~ predicted_risk, 
  data = df_test_dca, 
  fitted.risk = TRUE, 
  thresholds = seq(0, 1, by = 0.01),
  confidence.intervals = FALSE,  # 不计算置信区间
  bootstraps = 0  # 不使用 Bootstrap
)

# Step 5: 绘制决策曲线，仅保留决策曲线本身
# 绘制训练集的决策曲线
plot_decision_curve(
  x = list(dca_train), 
  curve.names = c("Nomogram"), 
  cost.benefit.axis = TRUE,        # 显示代价-效益轴
  n.cost.benefits = 6,             # 设置代价-效益刻度数
  standardize = TRUE,              # 标准化曲线
  #confidence.intervals = 0.95,     # 绘制 95% 置信区间
  col = "blue",                    # 设置训练集曲线颜色
  lty = 1,                         # 设置线型，1 为实线
  lwd = 2,                         # 设置线宽
  xlim = c(0, 1),                  # 设置 X 轴范围
  ylim = c(-0.05, 1),            # 设置 Y 轴范围
  xlab = "Threshold Probability",  # 自定义 X 轴标签
  ylab = "Net Benefit",            # 自定义 Y 轴标签
  legend.position = "topright"     # 图例位置
)

# 绘制测试集的决策曲线
plot_decision_curve(
  x = list(dca_test), 
  curve.names = c("Nomogram"), 
  cost.benefit.axis = TRUE,        # 显示代价-效益轴
  n.cost.benefits = 6,             # 设置代价-效益刻度数
  standardize = TRUE,              # 标准化曲线
  #confidence.intervals = 0.95,     # 不绘制 95% 置信区间
  col = "red",                     # 设置测试集曲线颜色
  lty = 1,                         # 设置线型，2 为虚线
  lwd = 2,                         # 设置线宽
  xlim = c(0, 1),                  # 设置 X 轴范围
  ylim = c(-0.05, 1),            # 设置 Y 轴范围
  xlab = "Threshold Probability",  # 自定义 X 轴标签
  ylab = "Net Benefit",            # 自定义 Y 轴标签
  legend.position = "topright"     # 图例位置
)
plot_decision_curve(
  x = list(dca_train, dca_test), 
  curve.names = c("Training Set", "Test Set"), 
  cost.benefit.axis = TRUE,  # 显示代价-效益轴
  n.cost.benefits = 6,       # 设置代价-效益刻度数
  standardize = TRUE,        # 标准化曲线
  confidence.intervals = FALSE,  # 不绘制 95% 置信区间
  col = c("blue", "red"),    # 设置 Training 和 Test 的曲线颜色
  lty = c(1, 1),             # 线型，1 表示实线
  lwd = 2,                   # 设置线宽
  xlim = c(0, 1),            # 设置 X 轴范围
  ylim = c(-0.05, 1),        # 设置 Y 轴范围
  xlab = "Threshold Probability",  # 自定义 X 轴标签
  ylab = "Net Benefit",           # 自定义 Y 轴标签
  legend.position = "topright"     # 图例位置
)
# ================================
###曲线交点标记(已完成)
# ================================
if (FALSE)
{
  # ================================
  ###训练集曲线交点标记
  # ================================
  str(dca_train)
  dca_train_derived_data <- dca_train$derived.data
  str(dca_train_derived_data)
  
  # 找到 model 列为 "All" 时首次 NB 为负数时的 thresholds
  threshold_all_negative <- dca_train_derived_data %>%
    filter(model == "All", NB < 0) %>%
    slice(1) %>%
    pull(thresholds)
  
  # 找到 model 列为 "y ~ predicted_risk" 时首次 NB 为负数时的 thresholds
  threshold_predicted_negative <- dca_train_derived_data %>%
    filter(model == "y ~ predicted_risk", NB < 0) %>%
    slice(1) %>%
    pull(thresholds)
  
  # 列举所有 thresholds 值，使 model 列的值为 "y ~ predicted_risk" 时 NB 的值比 model 列的值为 "All" 时 NB 的值小
  comparison_thresholds <- dca_train_derived_data %>%
    filter(model == "y ~ predicted_risk") %>%
    inner_join(
      dca_train_derived_data %>%
        filter(model == "All") %>%
        select(thresholds, NB) %>%
        rename(NB_all = NB),
      by = "thresholds"
    ) %>%
    filter(NB < NB_all) %>%
    select(thresholds)
  # 输出结果
  print(threshold_all_negative)
  print(threshold_predicted_negative)
  print(comparison_thresholds)
  
  # ================================
  ###测试集曲线交点标记
  # ================================
  
  # 假设 dca_test 的结构类似 dca_train，先提取其 derived.data 部分
  dca_test_derived_data <- dca_test$derived.data
  
  # 找到 model 列为 "All" 时首次 NB 为负数时的 thresholds
  threshold_all_negative_test <- dca_test_derived_data %>%
    filter(model == "All", NB < 0) %>%
    slice(1) %>%
    pull(thresholds)
  # 列举所有 thresholds 值，使 model 列的值为 "y ~ predicted_risk" 时 NB 的值比 model 列的值为 "All" 时 NB 的值小
  comparison_thresholds_test <- dca_test_derived_data %>%
    filter(model == "y ~ predicted_risk") %>%
    inner_join(
      dca_test_derived_data %>%
        filter(model == "All") %>%
        select(thresholds, NB) %>%
        rename(NB_all = NB),
      by = "thresholds"
    ) %>%
    filter(NB < NB_all) %>%
    select(thresholds)
  # 输出结果
  print(threshold_all_negative_test)
  print(comparison_thresholds_test)
  
  
}

# ================================
######绘制rms-lrm的ROC曲线
# ================================

# 初始化 summary_table
summary_table <- data.frame(
  Dataset = character(),
  AUC = numeric(),
  Best_Cutoff = numeric(),
  Sensitivity = numeric(),
  Specificity = numeric(),
  PPV = numeric(),
  NPV = numeric(),
  Accuracy = numeric(),
  stringsAsFactors = FALSE
)

# 1. 加载 pROC 包
library(pROC)

# 2. 获取预测概率
prob_train <- predict(fit_rms, newdata = df_train_selected, type = "fitted")
prob_test <- predict(fit_rms, newdata = df_test_selected, type = "fitted")

# 3. 计算 ROC 和 AUC
roc_train <- roc(df_train_selected$y, prob_train)
roc_test <- roc(df_test_selected$y, prob_test)

# 4. 计算最佳阈值及相关指标
coords_train <- coords(roc_train, "best", ret = c("threshold", "specificity", "sensitivity"))
best_threshold_train <- coords_train$threshold
best_sensitivity_train <- coords_train$sensitivity
best_specificity_train <- coords_train$specificity

coords_test <- coords(roc_test, "best", ret = c("threshold", "specificity", "sensitivity"))
best_threshold_test <- coords_test$threshold
best_sensitivity_test <- coords_test$sensitivity
best_specificity_test <- coords_test$specificity

# 5. 计算混淆矩阵及指标
# 训练集
predicted_train <- ifelse(prob_train >= best_threshold_train, 1, 0)
confusion_train <- table(Predicted = predicted_train, Actual = df_train_selected$y)

sensitivity_train <- confusion_train[2, 2] / sum(confusion_train[, 2])  # TP / (TP + FN)
specificity_train <- confusion_train[1, 1] / sum(confusion_train[, 1])  # TN / (TN + FP)
PPV_train <- confusion_train[2, 2] / sum(confusion_train[2, ])          # TP / (TP + FP)
NPV_train <- confusion_train[1, 1] / sum(confusion_train[1, ])          # TN / (TN + FN)
accuracy_train <- sum(diag(confusion_train)) / sum(confusion_train)     # (TP + TN) / Total

# 测试集
predicted_test <- ifelse(prob_test >= best_threshold_test, 1, 0)
confusion_test <- table(Predicted = predicted_test, Actual = df_test_selected$y)

sensitivity_test <- confusion_test[2, 2] / sum(confusion_test[, 2])  # TP / (TP + FN)
specificity_test <- confusion_test[1, 1] / sum(confusion_test[, 1])  # TN / (TN + FP)
PPV_test <- confusion_test[2, 2] / sum(confusion_test[2, ])          # TP / (TP + FP)
NPV_test <- confusion_test[1, 1] / sum(confusion_test[1, ])          # TN / (TN + FN)
accuracy_test <- sum(diag(confusion_test)) / sum(confusion_test)     # (TP + TN) / Total

# 6. 添加结果到 summary_table
summary_table <- rbind(
  summary_table,
  data.frame(
    Dataset = "Train",
    AUC = auc(roc_train),
    Best_Cutoff = best_threshold_train,
    Sensitivity = sensitivity_train,
    Specificity = specificity_train,
    PPV = PPV_train,
    NPV = NPV_train,
    Accuracy = accuracy_train
  ),
  data.frame(
    Dataset = "Test",
    AUC = auc(roc_test),
    Best_Cutoff = best_threshold_test,
    Sensitivity = sensitivity_test,
    Specificity = specificity_test,
    PPV = PPV_test,
    NPV = NPV_test,
    Accuracy = accuracy_test
  )
)

# 打印 summary_table
print(summary_table)

# 设置导出路径
file_path <- "C:/Users/ZXC/Desktop/summary_table.xlsx"

# 将数据框写入 Excel 文件
write.xlsx(summary_table, file = file_path)
# 7. 绘制 ROC 曲线
ci_train <- ci.auc(roc_train)
ci_test <- ci.auc(roc_test)

# 绘制训练集 ROC 曲线
plot(
  roc_train, 
  col = "blue", 
  main = "ROC Curve for Logistic Model (Train)", 
  lwd = 2
)
legend(
  "bottomright",
  legend = paste0(
    "AUC = ", round(auc(roc_train), 3), 
    " (95% CI: ", round(ci_train[1], 3), "-", round(ci_train[3], 3), ")"
  ),
  col = "blue",
  lwd = 2
)

# 绘制测试集 ROC 曲线
plot(
  roc_test, 
  col = "red", 
  main = "ROC Curve for Logistic Model (Test)", 
  lwd = 2
)
legend(
  "bottomright",
  legend = paste0(
    "AUC = ", round(auc(roc_test), 3), 
    " (95% CI: ", round(ci_test[1], 3), "-", round(ci_test[3], 3), ")"
  ),
  col = "red",
  lwd = 2
)

# 绘制训练集和测试集对比 ROC 曲线
plot(roc_train, col = "blue", main = "ROC Curve - Training vs Test Set", lwd = 2)
plot(roc_test, col = "red", add = TRUE, lwd = 2)
legend(
  "bottomright",
  legend = c(
    paste0("Train: AUC = ", round(auc(roc_train), 3), 
           " (95% CI: ", round(ci_train[1], 3), "-", round(ci_train[3], 3), ")"),
    paste0("Test: AUC = ", round(auc(roc_test), 3), 
           " (95% CI: ", round(ci_test[1], 3), "-", round(ci_test[3], 3), ")")
  ),
  col = c("blue", "red"),
  lwd = 2
)
